{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Graph feature extraction"],"metadata":{"id":"TzJ5HxzLePkc"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"cPoYFsfYebYG"}},{"cell_type":"markdown","source":["Install libraries:\n","- standard data science stack (Numpy, Pandas, Scikit-learn, tqdm)\n","- graph libraries (NetworkX, NetworKit)\n","- deep learning on graphs (PyTorch, PyTorch Scatter, PyTorch Geometric)\n","\n","For PyTorch Scatter, we use a small workaround for Google Colab - change PyTorch or Python version if necessary."],"metadata":{"id":"tWD4nzvqexRR"}},{"cell_type":"code","source":["!pip install numpy pandas scikit-learn tqdm networkx networkit torch torch_geometric --extra-index-url https://download.pytorch.org/whl/cpu"],"metadata":{"id":"I6U3WCeUeaw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp310-cp310-linux_x86_64.whl"],"metadata":{"id":"xy8zjdi0hL7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data loading"],"metadata":{"id":"P_P7e3WCeWoA"}},{"cell_type":"markdown","source":["We will use **IMDB-BINARY** dataset:\n","- a movie collaboration dataset\n","- each graph represents a set of actors playing in movies from genre: Action or Romance\n","- graphs are **ego-networks** (who-knows-whom), nodes are actors, edges mean that actors appear in the same movie\n","- statistics:\n","  - 1000 graphs\n","  - 2 classes\n","  - avg # nodes: 19.8\n","  - avg # edges: 193.1\n","  - no node/edge features\n","\n","So we have to predict the genre of the movies, based only on actors interactions!\n","\n","Dataset hosted by TU Dortmund University at [TUDataset](https://chrsmrrs.github.io/datasets/docs/datasets/)."],"metadata":{"id":"ptQpmpa4gMCV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qkmr_Dv9eII4"},"outputs":[],"source":["import pandas as pd\n","from torch_geometric.data import Dataset\n","from torch_geometric.datasets import TUDataset\n","\n","\n","dataset = TUDataset(\n","    root=\"data\",  # where to save dataset\n","    name=\"IMDB-BINARY\"\n",")\n","\n","print(f\"Number of classes: {dataset.num_classes}\")\n","print()\n","dataset.print_summary()\n","print()\n","pd.Series(dataset.y).value_counts().plot.bar(title=\"Class distribution\")"]},{"cell_type":"markdown","source":["### PyTorch Geometric Dataset\n","\n","1. Built from graphs\n","2. Regular PyTorch dataset, with indexing etc.\n","3. Collection of `Data` objects, representing graphs:\n","   - `edge_index` - adjacency matrix in COO sparse format\n","   - `num_nodes` - $|V|$\n","   - `x` - node features\n","   - `y` - class"],"metadata":{"id":"PWNmvwRNmBGh"}},{"cell_type":"code","source":["graph = dataset[0]\n","\n","print(\"Graph:\", graph)\n","print(\"Adjacency matrix (COO sparse format):\", graph.edge_index)\n","print(\"Number of nodes:\", graph.num_nodes)\n","print(\"Node features:\", graph.x)\n","print(\"Class:\", graph.y)"],"metadata":{"id":"ta8coJTdlusk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Local Degree Profile (LDP)"],"metadata":{"id":"SGG3dPLbnDBu"}},{"cell_type":"markdown","source":["1. Extract LDP features\n","2. Gather features for all graphs\n","3. Classify with Random Forest\n","\n","We will use [PyTorch Geometric code for LDP](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/transforms/local_degree_profile.html), but slightly modified."],"metadata":{"id":"Jq9F_49Vn1qp"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch_geometric.data import Data\n","from torch_geometric.nn.aggr.fused import FusedAggregation\n","from torch_geometric.utils import degree\n","\n","\n","def extract_ldp_features(graph: Data) -> np.ndarray:\n","    row, col = graph.edge_index\n","    N = graph.num_nodes\n","\n","    # compute degree for each node, using adjacency matrix\n","\n","    # compute degree statistics, using node degrees and adjacency matrix\n","\n","    # combine features into a single list of Numpy vectors\n","\n","    # aggregate each feature with a histogram and concatenate them\n","\n","    return aggregated_features\n"],"metadata":{"id":"YtX5zVIHmAnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","\n","\n","def dataset_to_ldp_features(dataset: Dataset) -> np.ndarray:\n","    X = []\n","    for graph in tqdm(dataset, total=len(dataset)):\n","        x = extract_ldp_features(graph)\n","        X.append(x)\n","\n","    return np.stack(X)\n"],"metadata":{"id":"QaMjICiNp0y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","\n","def train_ldp(dataset: Dataset) -> None:\n","    clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n","    X = dataset_to_ldp_features(dataset)\n","    y = dataset.y.numpy()\n","\n","    scores = cross_val_score(\n","        estimator=clf,\n","        X=X,\n","        y=y,\n","        scoring=\"accuracy\",\n","        cv=10,\n","    )\n","    test_acc = np.mean(scores)\n","    print(f\"Test accuracy: {100 * test_acc:.2f}\")\n"],"metadata":{"id":"DxKhrz3Bo5xw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ldp(dataset)"],"metadata":{"id":"nHAt6CWpuuPB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Local Topological Profile (LTP)\n","\n","1. Extract LDP features\n","2. Transform to NetworKit graph\n","3. Calculate additional LTP features\n","4. Gather features for all graphs\n","5. Classify with Random Forest\n","\n","We will use NetworKit tutorials:\n","- [edge betweenness centrality](https://networkit.github.io/dev-docs/notebooks/Centrality.html)\n","- [Jaccard index](https://networkit.github.io/dev-docs/notebooks/LinkPrediction.html)\n","- [Local Degree Score](https://networkit.github.io/dev-docs/notebooks/Sparsification.html)"],"metadata":{"id":"vpqSLZ08vuIq"}},{"cell_type":"code","source":["from networkit.centrality import Betweenness\n","from networkit.graph import Graph as NetworkitGraph\n","from networkit.linkprediction import JaccardIndex\n","from networkit.nxadapter import nx2nk\n","from networkit.sparsification import LocalDegreeScore\n","from torch_geometric.utils import to_networkx\n","\n","\n","def calculate_edge_betweenness(graph: NetworkitGraph) -> np.ndarray:\n","    # calculate betweenness and get edge scores\n","\n","    # to Numpy\n","    scores = np.array(scores, dtype=np.float32)\n","    return scores\n","\n","\n","def calculate_jaccard_index(graph: NetworkitGraph) -> np.ndarray:\n","    # calculate Jaccard index values\n","\n","    # to Numpy, remove infinite values\n","    scores = np.array(scores, dtype=np.float32)\n","    scores = scores[np.isfinite(scores)]\n","    return scores\n","\n","\n","def calculate_local_degree_score(graph: NetworkitGraph) -> np.ndarray:\n","    # calculate Local Degree Score values\n","\n","    # to Numpy\n","    scores = np.array(scores, dtype=np.float32)\n","    return scores\n","\n","\n","def extract_ltp_features(graph: Data) -> np.ndarray:\n","    row, col = graph.edge_index\n","    N = graph.num_nodes\n","\n","    # compute degree for each node, using adjacency matrix\n","\n","    # compute degree statistics, using node degrees and adjacency matrix\n","\n","    # combine features into a single list of Numpy vectors\n","\n","    # transform to NetworKit\n","    graph_networkx = to_networkx(graph, to_undirected=True)\n","    graph_networkit = nx2nk(graph_networkx)\n","    graph_networkit.indexEdges()\n","\n","    # calculate additional features\n","    ebc = calculate_edge_betweenness(graph_networkit)\n","    jaccard_index = calculate_jaccard_index(graph_networkit)\n","    lds = calculate_local_degree_score(graph_networkit)\n","\n","    features.extend([ebc, jaccard_index, lds])\n","\n","    # aggregate each feature with a histogram and concatenate them\n","\n","\n","    return aggregated_features\n"],"metadata":{"id":"dEcS-MWxvwOE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_to_ltp_features(dataset: Dataset) -> np.ndarray:\n","    X = []\n","    for graph in tqdm(dataset, total=len(dataset)):\n","        x = extract_ltp_features(graph)\n","        X.append(x)\n","\n","    return np.stack(X)\n"],"metadata":{"id":"iEtCNTiOx4hj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","\n","def train_ltp(dataset: Dataset) -> None:\n","    clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n","    X = dataset_to_ltp_features(dataset)\n","    y = dataset.y.numpy()\n","\n","    scores = cross_val_score(\n","        estimator=clf,\n","        X=X,\n","        y=y,\n","        scoring=\"accuracy\",\n","        cv=10,\n","    )\n","    test_acc = np.mean(scores)\n","    print(f\"Test accuracy: {100 * test_acc:.2f}\")\n"],"metadata":{"id":"hQN6cCphx-z-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ltp(dataset)"],"metadata":{"id":"6v0aXK7EyAag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ectpGtiRy2LO"},"execution_count":null,"outputs":[]}]}