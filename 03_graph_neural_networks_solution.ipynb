{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Graph neural networks"],"metadata":{"id":"TzJ5HxzLePkc"}},{"cell_type":"markdown","source":["## Setup\n","\n","Install libraries:\n","- standard data science stack (Matplotlib, Numpy, Pandas, Scikit-learn, tqdm)\n","- deep learning on graphs (PyTorch, PyTorch Geometric, pyg-lib)\n","- OGB (Open Graph Benchmark) for loading benchmark datasets and evaluators"],"metadata":{"id":"tWD4nzvqexRR"}},{"cell_type":"code","source":["!pip install numpy pandas scikit-learn tqdm torch ogb --extra-index-url https://download.pytorch.org/whl/cu118"],"metadata":{"id":"I6U3WCeUeaw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch_geometric pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+cu118.html"],"metadata":{"id":"xy8zjdi0hL7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data loading\n","\n","We will use **HIV** dataset:\n","- a molecular property prediction\n","- each graph represents a molecule, which inhibits (prevents) HIV virus replication or not\n","- nodes are atoms, edges are bonds\n","- statistics:\n","  - 41,127 graphs\n","  - 2 classes\n","  - avg # nodes: 25.5\n","  - avg # edges: 27.5\n","  - 9 node features, e.g. atom type, chirality, formal charge\n","  - 3 edge features, e.g. bond type\n","- imbalanced classification, AUROC metric\n","\n","Dataset is originally from MoleculeNet benchmark:\n","> Wu, Z., et al. \"MoleculeNet: a benchmark for molecular machine learning.\"\n","\n","It is hosted by [Open Graph Benchmark](https://ogb.stanford.edu/), which offers:\n","- standardized train/valid/test split\n","- challenging scaffold split\n","- unified evaluation procedure & metrics\n","- leaderboard"],"metadata":{"id":"ptQpmpa4gMCV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qkmr_Dv9eII4"},"outputs":[],"source":["import pandas as pd\n","from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n","\n","\n","dataset = PygGraphPropPredDataset(\n","    name=\"ogbg-molhiv\",\n","    root=\"data\"\n",")\n","evaluator = Evaluator(\"ogbg-molhiv\")\n","\n","print(f\"Number of classes: {dataset.num_classes}\")\n","print()\n","dataset.print_summary()\n","print()\n","print(f\"Number of node features: {dataset.num_node_features}\")\n","print()\n","print(f\"Model metric: {dataset.eval_metric}\")\n","print()\n","print(f\"Number of tasks: {dataset.num_tasks}\")\n","print()\n","pd.Series(dataset.y.flatten()).value_counts().plot.bar(title=\"Class distribution\")"]},{"cell_type":"markdown","source":["## Data splits\n","\n","Use **scaffold split**:\n","- splits on \"scaffold\", i.e. \"core\" of the molecule\n","- validation and test sets are novel, very different molecules\n","- forces **out-of-distribution generalization**\n","- very realistic for de novo drug design\n"],"metadata":{"id":"PWNmvwRNmBGh"}},{"cell_type":"code","source":["import torch\n","from torch_geometric.loader import DataLoader\n","\n","\n","BATCH_SIZE = 32\n","NUM_WORKERS = 1\n","\n","\n","split_idx = dataset.get_idx_split()\n","\n","torch.manual_seed(0)\n","train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)\n","valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)\n","test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n"],"metadata":{"id":"ta8coJTdlusk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch training code"],"metadata":{"id":"SLnaIR345mmK"}},{"cell_type":"markdown","source":["Regular PyTorch boilerplate, nothing GNN-specific."],"metadata":{"id":"iofsGAu_Atqz"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm\n","\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device(\"cpu\"))\n","\n","\n","def train_model_epoch(\n","    model: nn.Module,\n","    loader: DataLoader,\n","    optimizer: optim.Optimizer\n",") -> None:\n","    model.train()\n","\n","    for batch in tqdm(loader, desc=\"Train iteration\"):\n","        batch = batch.to(DEVICE)\n","        optimizer.zero_grad()\n","\n","        y_pred = model(batch)\n","        y_true = batch.y.to(torch.float32)\n","\n","        loss = F.binary_cross_entropy_with_logits(y_pred, y_true)\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","def eval_model(model: nn.Module, loader: DataLoader) -> None:\n","    model.eval()\n","    y_true_all = []\n","    y_pred_all = []\n","\n","    for batch in tqdm(loader, desc=\"Eval iteration\"):\n","        batch = batch.to(DEVICE)\n","\n","        with torch.no_grad():\n","            y_pred = model(batch)\n","\n","        y_true = batch.y.view(y_pred.shape).detach().cpu()\n","        y_pred = y_pred.detach().cpu()\n","\n","        y_true_all.append(y_true)\n","        y_pred_all.append(y_pred)\n","\n","    y_true_all = torch.cat(y_true_all, dim=0).numpy()\n","    y_pred_all = torch.cat(y_pred_all, dim=0).numpy()\n","\n","    input_dict = {\"y_true\": y_true_all, \"y_pred\": y_pred_all}\n","    eval_result = evaluator.eval(input_dict)\n","\n","    return eval_result\n","\n","\n","def train_gnn(\n","    model: nn.Module,\n","    train_loader: DataLoader,\n","    valid_loader: DataLoader,\n","    test_loader: DataLoader,\n","    num_epochs: int = 5,\n","    learning_rate: float = 1e-3\n","):\n","    torch.manual_seed(0)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    best_valid_score = -1\n","    best_model_path = \"best_model\"\n","\n","    for epoch in range(1, num_epochs + 1):\n","        print(f\"=====Epoch {epoch}\")\n","        train_model_epoch(model, train_loader, optimizer)\n","\n","        train_eval = eval_model(model, train_loader)\n","        valid_eval = eval_model(model, valid_loader)\n","\n","        train_metric = 100 * train_eval[dataset.eval_metric]\n","        valid_metric = 100 * valid_eval[dataset.eval_metric]\n","\n","        print(f\"Metrics (AUROC): training {train_metric:.2f}, validation {valid_metric:.2f}\")\n","\n","        if valid_metric > best_valid_score:\n","            best_valid_score = valid_metric\n","            torch.save(model.state_dict(), best_model_path)\n","\n","    print(\"Finished training!\")\n","\n","    model.load_state_dict(torch.load(best_model_path))\n","    test_eval = eval_model(model, test_loader)\n","    test_metric = 100 * test_eval[dataset.eval_metric]\n","\n","    print(f\"Test AUROC: {test_metric:.2f}\")\n"],"metadata":{"id":"EzMDYYZb5lcA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Graph Convolutional Network (GCN) model\n","\n","We'll use only node features now, but with **embedding**:\n","- linear layer before using features\n","- casts 10 features into high-dimensional space\n","- simple trick to add more expressiveness & make everything continous\n","- inspired by word embeddings in transformers\n","\n","We'll also use **dropout**, which will randomly zero some hidden features between layers."],"metadata":{"id":"MCxJh-2GAzZR"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","from torch.nn import Linear\n","from ogb.graphproppred.mol_encoder import AtomEncoder\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCN, global_mean_pool\n","\n","\n","class GCNGraphClassifier(torch.nn.Module):\n","    def __init__(self, hidden_channels: int, num_layers: int, dropout: float):\n","        super().__init__()\n","        torch.manual_seed(0)\n","\n","        # initial input embedding\n","        self.atom_encoder = AtomEncoder(hidden_channels)\n","\n","        # GNN backbone\n","        self.gnn = GCN(\n","            in_channels=hidden_channels,\n","            hidden_channels=hidden_channels,\n","            num_layers=num_layers,\n","            dropout=dropout,\n","            act=\"relu\",\n","        )\n","\n","        # MLP head\n","        self.mlp = Linear(hidden_channels, out_features=1)\n","\n","    def forward(self, data_batch: Data):\n","        x = data_batch.x                    # node features\n","        edge_index = data_batch.edge_index  # adjacency matrices\n","        batch = data_batch.batch            # individual graph indicators\n","\n","        # calculate initial input embeddings\n","        x = self.atom_encoder(x)\n","\n","        # calculate node embeddings\n","        x = self.gnn(x, edge_index)\n","\n","        # readout (global pooling)\n","        x = global_mean_pool(x, batch)\n","\n","        # classify\n","        x = self.mlp(x)\n","\n","        return x\n"],"metadata":{"id":"ectpGtiRy2LO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GCNGraphClassifier(hidden_channels=256, num_layers=3, dropout=0.5)\n","model.to(DEVICE)\n","train_gnn(model, train_loader, valid_loader, test_loader)"],"metadata":{"id":"MO_1a4nlDheh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Graph Attention Network (GAT)\n","\n","We'll swap GCN to GAT convolution, and also use **edge features**.\n","\n","There is a simple trick to use them:\n","- embed edge features to the same dimensionality as nodes\n","- add neighbor node features with its edge features\n","- use this summed vector as neighbor message\n","\n","We also use less dropout - attention should cover this for us."],"metadata":{"id":"eFUzQ30ATZ1M"}},{"cell_type":"code","source":["from ogb.graphproppred.mol_encoder import BondEncoder\n","from torch_geometric.nn import GAT, global_mean_pool\n","\n","\n","class GATGraphClassifier(torch.nn.Module):\n","    def __init__(self, hidden_channels: int, num_layers: int, dropout: float):\n","        super().__init__()\n","        torch.manual_seed(0)\n","\n","        # initial input embedding\n","        self.atom_encoder = AtomEncoder(hidden_channels)\n","        self.bond_encoder = BondEncoder(hidden_channels)\n","\n","        # GNN backbone\n","        self.gnn = GAT(\n","            in_channels=hidden_channels,\n","            hidden_channels=hidden_channels,\n","            num_layers=num_layers,\n","            dropout=dropout,\n","            act=\"relu\",\n","        )\n","\n","        # MLP head\n","        self.mlp = Linear(hidden_channels, out_features=1)\n","\n","    def forward(self, data_batch: Data):\n","        x = data_batch.x                    # node features\n","        edge_index = data_batch.edge_index  # adjacency matrices\n","        batch = data_batch.batch            # individual graph indicators\n","        edge_attr = data_batch.edge_attr    # edge features\n","\n","        # calculate initial input embeddings\n","        x = self.atom_encoder(x)\n","        edge_attr = self.bond_encoder(edge_attr)\n","\n","        # calculate node embeddings\n","        x = self.gnn(x, edge_index, edge_attr=edge_attr)\n","\n","        # readout (global pooling)\n","        x = global_mean_pool(x, batch)\n","\n","        # classify\n","        x = self.mlp(x)\n","\n","        return x\n"],"metadata":{"id":"XgwlwXASTZLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GATGraphClassifier(hidden_channels=256, num_layers=3, dropout=0.2)\n","model.to(DEVICE)\n","train_gnn(model, train_loader, valid_loader, test_loader)"],"metadata":{"id":"012WR42QU6fu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Graph Isomorphism Network (GIN)\n","\n","GIN architecture elements, based on GIN paper and OGB benchmark (same author):\n","- sum readout instead of mean\n","- Jumping Knowledge with concatenation\n","- 5 layers instead of 3\n","\n","Other notes:\n","- use edge features\n","- go back to stronger dropout, since this is much more expressive\n","- train for longer, since we have much more parameters"],"metadata":{"id":"d7fO80HxR8Cd"}},{"cell_type":"code","source":["from torch_geometric.nn import GIN, global_add_pool\n","\n","\n","class GINGraphClassifier(torch.nn.Module):\n","    def __init__(self, hidden_channels: int, num_layers: int, dropout: float):\n","        super().__init__()\n","        torch.manual_seed(0)\n","\n","        # initial input embedding\n","        self.atom_encoder = AtomEncoder(hidden_channels)\n","        self.bond_encoder = BondEncoder(hidden_channels)\n","\n","        out_channels = hidden_channels * num_layers\n","\n","        # GNN backbone\n","        self.gnn = GIN(\n","            in_channels=hidden_channels,\n","            hidden_channels=hidden_channels,\n","            num_layers=num_layers,\n","            out_channels=out_channels,\n","            dropout=dropout,\n","            act=\"relu\",\n","            jk=\"cat\",\n","        )\n","\n","        # MLP head\n","        self.mlp = Linear(out_channels, out_features=1)\n","\n","    def forward(self, data_batch: Data):\n","        x = data_batch.x                    # node features\n","        edge_index = data_batch.edge_index  # adjacency matrices\n","        batch = data_batch.batch            # individual graph indicators\n","        edge_attr = data_batch.edge_attr    # edge features\n","\n","        # calculate initial input embeddings\n","        x = self.atom_encoder(x)\n","        edge_attr = self.bond_encoder(edge_attr)\n","\n","        # calculate node embeddings\n","        x = self.gnn(x, edge_index, edge_attr=edge_attr)\n","\n","        # readout (global pooling)\n","        x = global_add_pool(x, batch)\n","\n","        # classify\n","        x = self.mlp(x)\n","\n","        return x\n"],"metadata":{"id":"qntayuCpDt9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GINGraphClassifier(hidden_channels=256, num_layers=5, dropout=0.5)\n","model.to(DEVICE)\n","train_gnn(model, train_loader, valid_loader, test_loader, num_epochs=10)"],"metadata":{"id":"KW2sjvcKTEPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UUcnr1wgTGft"},"execution_count":null,"outputs":[]}]}